<section>
        <title>Équations linéaires scalaires du deuxième ordre</title>

        <warning>
            <p>Sous le thème des équations différentielles, les équations linéaires scalaires du deuxième ordre sont les équations les plus fréquemment abordées dans les sujets de concours.</p>
        </warning>

        <convention>
            <p>Soient <m>a, b, c</m> et <m>\varphi</m> des applications continues de <m>I</m> dans <m>\K</m>. On considère l'EDLS du deuxième ordre :
            <me>
                a(t)x'' + b(t)x' + c(t)x = \varphi(t)
            </me></p>
            <p>Une solution de <m>(E)</m> sur <m>I</m> est une fonction <m>f: I \to \K</m> telle que :
            <ul>
                <li><m>f</m> est deux fois dérivable sur <m>I</m> ;</li>
                <li><m>\forall t \in I, \; a(t)f''(t) + b(t)f'(t) + c(t)f(t) = \varphi(t)</m>.</li>
            </ul></p>
            <p>L'équation <m>(E)</m> est dite normalisée si <m>a</m> est constante de valeur <m>1</m> et normalisable si <m>a</m> ne s'annule pas sur <m>I</m>.</p>
            <aside>
                <title>Remarque</title>
                <p>Si <m>(E)</m> est normalisable, alors elle est équivalente à l'équation normalisée obtenue en la divisant par <m>a(t)</m>. En général, <m>(E)</m> est équivalente à toute équation de la forme :
                <me>
                    a(t)\omega(t)x'' + b(t)\omega(t)x' + c(t)\omega(t)x = \varphi(t)\omega(t)
                </me></p>
                <p>où <m>\omega</m> est une fonction continue qui ne s'annule pas sur <m>I</m>.</p>
            </aside>
            <p>Attention donc, les résultats du cadre général ne sont applicables à <m>(E)</m> que si elle est normalisable. En particulier, la dimension de l'ensemble <m>S_I(H)</m> des solutions de l'équation homogène peut être strictement supérieure à <m>2</m>.</p>
            <p>Dans le cas où <m>(E)</m> est normalisable, elle équivaut au système différentiel :
            <md>
                <mrow> (SE) \amp\amp X' \amp= A(t)X + B(t)</mrow>
            </md>
            où 
            <me>
                X(t) = \begin{pmatrix} x(t) \\ x'(t) \end{pmatrix}, \quad
                A(t) = \begin{pmatrix}
                0 \amp 1 \\
                -\frac{c(t)}{a(t)} \amp -\frac{b(t)}{a(t)}
                \end{pmatrix}, \quad
                B(t) = \begin{pmatrix} 0 \\ \frac{\varphi(t)}{a(t)} \end{pmatrix}
            </me>
            </p>
            <p>On notera <m>(H)</m> l'équation homogène de <m>(E)</m> et <m>(SH)</m> celle de <m>(SE)</m>.</p>
        </convention>

        <assemblage>
            <title>Récapitulatif</title>
            <p>Dans cette rubrique, on ne fera qu'adapter les énoncés du cadre général au cas particulier d'une EDLS du deuxième ordre normalisable.</p>
            <p>On suppose donc que l'équation <m>(E)</m> est normalisable.
            <ol>
                <li>
                    <title>Théorème de Cauchy-Lipschitz</title> 
                    <p>Pour tout <m>(t_0, x_0, x_0') \in I \times \K^2</m>, il existe une unique solution <m>f</m> de <m>(E)</m> telle que :</p>
                    <me>
                        f(t_0) = x_0 \quad \text{et} \quad f'(t_0) = x_0'
                    </me>
                </li>
                <li>
                    <title>Structure des ensembles de solutions</title> 
                     <p><m>S_I(H)</m> est un <m>\K</m>-espace vectoriel de dimension <m>2</m>, et <m>S_I(E) = f_0 + S_I(H)</m> pour toute solution <m>f_0</m> de <m>(E)</m> sur <m>I</m>.</p>
                </li>
                <li>
                    <title>Système de solutions et wronskien</title> 
                    <p> Si <m>f_1</m> et <m>f_2</m> sont des solutions de l'équation homogène <m>(H)</m>, on appelle wronskien de <m>f_1</m> et <m>f_2</m> la fonction <m>w</m> définie par :</p>
                    <me>
                        w(t) = \begin{vmatrix} f_1(t) \amp f_2(t) \\ f_1'(t) \amp f_2'(t) \end{vmatrix}
                    </me>
                    <p>La famille <m>(f_1, f_2)</m> est une base de <m>S_I(H)</m> si et seulement si <m>w</m> ne s'annule pas sur <m>I</m>. Pour cela, il suffit qu'il ne s'annule pas en un point de <m>I</m>.</p>
                </li>
                <li>
                    <title>Équation du wronskien</title> 
                    <aside>
                        <p>Le wronskien de deux solutions de <m>(H)</m> ne dépend donc pas de la fonction <m>c</m>.</p>
                    </aside>
                    <p>Soit <m>w</m> le wronskien de deux solutions quelconques de <m>(H)</m>. Alors :</p>
                    <me>
                        \forall t \in I, \; a(t)w'(t) + b(t)w(t) = 0
                    </me>  
                </li>
                <li>
                    <title>Variations des constantes</title> 
                    <p>On suppose qu'on connaît une base <m>(f_1, f_2)</m> de <m>S_I(H)</m>. On note <m>w</m> leur wronskien. En remplaçant <m>X</m> par <m>\lambda_1(t)\mathbf{V} f_1 + \lambda_2(t)\mathbf{V} f_2(t)</m> dans le système différentiel <m>(SE)</m>, alors :</p>
                    <me>
                        (E)  \Longleftrightarrow \begin{cases}
                        \lambda_1'(t)f_1(t) + \lambda_2'(t)f_2(t) = 0 \\
                        \lambda_1'(t)f_1'(t) + \lambda_2'(t)f_2'(t) = \frac{\varphi(t)}{a(t)}
                        \end{cases}
                    </me>
                    <p>Les solutions de <m>(E)</m> sur <m>I</m> sont donc les fonctions :</p>
                    <me>
                        t \mapsto \lambda_1(t)f_1(t) + \lambda_2(t)f_2(t)
                    </me>
                    <p>où les fonctions <m>\lambda_1</m> et <m>\lambda_2</m> sont données par :
                    <me>
                        \lambda_1'(t) = -\frac{f_2(t)\varphi(t)}{a(t)w(t)}, \quad
                        \lambda_2'(t) = \frac{f_1(t)\varphi(t)}{a(t)w(t)}
                    </me></p> 
                    </li>
                    <li>
                        <title>Une solution particulière</title>
                            
                    <p>En fixant un point <m>t_0\in I</m>, on obtient une solution particulière <m>g</m> de <m>(E)</m> en posant  
                    <men xml:id="rawsol">
                        g(t) =-f_1(t)\int_{t_0}^t\frac{f_2(s)\varphi(s)}{a(s)w(s)}\mathrm{d}s+f_2(t)\int_{t_0}^t\frac{f_1(s)\varphi(s)}{a(s)w(s)}\mathrm{d}s
                    </men>
                    <md>
                        <mrow> \amp\text{ou encore}\amp\amp\amp g(t)\amp=\int_{t_0}^t\frac{\varphi(s)}{a(s)}H(t,s)\mathrm{d}s </mrow>
                    <mrow> \amp\text{avec}\amp\amp\amp H(t,s)\amp=\frac1{w(s)}\left|\begin{matrix} f_1(s) \amp f_1(t) \\ f_2(s) \amp f_2(t)\end{matrix}\right|
                    </mrow> 
                    </md>
                    en dérivant la relation <xref ref="rawsol"/> on voit en outre que 
                    <me>
                        g'(t)=\int_{t_0}^t\frac{\varphi(s)}{a(s)}\frac{\partial H}{\partial t}(t,s)\mathrm{d}s
                    </me>
                    De quoi on déduit que <m>g</m> est l'unique solution de <m>(E)</m> qui vérifie <m>g(t_0)=g'(t_0)=0</m>.
                    
                    </p>
                </li>
                <li>
                    <title>Expression complète des solutions de <m>(E)</m></title>  
                    <p>Les solutions de <m>(E)</m> sont ainsi les fonctions de la forme
                    <men xml:id="exprsol">
                        f(t) = \lambda_1 f_1(t) + \lambda_2 f_2(t) + \int_{t_0}^t \frac{\varphi(s)}{a(s)}H(t,s) \, ds
                    </men>
                    où <m>\lambda_1, \lambda_2</m> sont des scalaires quelconques dans <m>\K</m>.</p>
                </li>
                <li><title>Solution du problème de Cauchy</title>
                    <p>
                        Soient <m>x_0,x_0'\in\K</m>. Sur la base de la relation <xref ref="exprsol"/> l'unique solution <m>f</m> de <m>(E)</m> qui vérifie <m>f(t_0)=x_0</m> et <m>f'(t_0)=x_0'</m> est déterminée par le système linéaire d'inconnues <m>\lambda_1</m> et <m>\lambda_2</m> <nbsp/>:
                        <me>
                            \begin{cases}
                                f_1(t_0)\lambda_1+f_2(t_0)\lambda_2=x_0 \\
                                f_1'(t_0)\lambda_1+f_2'(t_0)\lambda_2=x_0'
                            \end{cases}
                        </me>
                    dont le déterminant est <m>w(t_0)</m>.
                    <!-- <me>
                        \lambda_1=\frac1{w(t_0)}\begin{vmatrix}x_0\amp f_2(t_0) \\ x_0'\amp f_2'(t_0)\end{vmatrix}
                        \qtext{et}
                        \lambda_2=-\frac1{w(t_0)}\begin{vmatrix}x_0\amp f_1(t_0) \\ x_0'\amp f_1'(t_0)\end{vmatrix}
                    </me>
                    <me>
                        \lambda_1f_1(t)+\lambda_2f_2(t)=\frac1{w(t_0)}
                        \begin{vmatrix}
                            x_0 \amp f_1(t)f_2(t_0)-f_2(t)f_1(t_0)\\
                            x_0' \amp f_1(t)f_2'(t_0)-f_1(t)f_1'(t_0)
                        \end{vmatrix}=
                        \begin{vmatrix}
                            x_0 \amp -H(t_0,t) \\
                            x_0' \amp \frac{\partial H}{\partial t}(t_0,t)
                        \end{vmatrix}
                    </me> -->

                    
                    </p>
                </li>
            </ol>
            </p>
        </assemblage>

        <assemblage>
    <title>Spécificités des <acro>EDLS</acro> du second ordre</title>
    <p>Dans cette rubrique, on examine quelques spécificités des équations linéaires scalaires du deuxième ordre. On considère les équations différentielles qu'on suppose normalisables sur <m>I</m> :
    <md>
        <mrow> (E) \amp\amp a(t) x'' + b(t) x' + c(t) x \amp = \varphi(t) </mrow>
        <mrow> (H) \amp\amp a(t) x'' + b(t) x' + c(t) x \amp = 0 </mrow>
    </md></p>
    <p><ol>
        <li>
            <title>Solutions passant par un même point </title>  
            <aside>
                <p>Chacune de ces solutions est entièrement déterminée par <m>f'(t_0)</m>.</p>
            </aside>
            <p>Pour tout <m>(t_0, x_0) \in I \times \K</m>, il existe une infinité de solutions <m>f</m> de <m>(E)</m> telles que <m>f(t_0) = x_0</m>.</p>
            
            <p>Si <m>f</m> et <m>g</m> sont des solutions distinctes de l'équation homogène <m>(H)</m> vérifiant la condition <m>x(t_0) = x_0</m>, alors <nbsp/>:
            <me>
                (f, g) \text{ est un SFS de } (H)  \Longleftrightarrow x_0 \neq 0
            </me></p>
            <explanation>
                <p><m>W(t_0) = x_0 (g'(t_0) - f'(t_0))</m> et puisque <m>f \neq g</m>, alors <m>f'(t_0) \neq g'(t_0)</m>.</p>
            </explanation>
        </li>
        <li>
            <title>Système fondamental canonique en un point</title> <p>Soit <m>t_0 \in I</m>. On appelle système fondamental canonique de solutions de <m>(H)</m> en <m>t_0</m> le couple <m>(f_0, f_1)</m> de solutions de <m>(H)</m> définies par :</p>
             <aside>
                <p><m>w(t_0) = 1</m>. <m>(f_0, f_1)</m> est bien un système fondamental de solutions de <m>(H)</m>.</p>
            </aside>
            <ul>
                <li><m>f_0(t_0) = 1</m>, <m>f_0'(t_0) = 0</m> ;</li>
                <li><m>f_1(t_0) = 0</m>, <m>f_1'(t_0) = 1</m>.</li>
            </ul>
            <p>L'intérêt et qu'on obtienne des expressions simplifiées des solutions de <m>(H)</m> et de <m>(E)</m><nbsp/>:</p>
            <ul>
                <li><p>Les solutions de <m>(H)</m> sont données par :
                <me>
                    f(t) = f(t_0) f_0(t) + f'(t_0) f_1(t)
                </me></p>
                </li>
                <li><p>Les solutions de <m>(E)</m> sont données par :
                <me>
                    f(t) = f(t_0) f_0(t) + f'(t_0) f_1(t) + \int_{t_0}^t H(t, s) \frac{\varphi(s)}{a(s)} \, ds
                </me>
                </p>
                </li>
            </ul>
            <p>pour rappel, <m>\ds H(t,s)=\frac1{w(s)}\left|\begin{matrix} f_0(s) \amp f_0(t) \\ f_1(s) \amp f_1(t)\end{matrix}\right|</m>.</p>
        </li>
        <li>
            <title>Wronskien croisé</title> 
            <p>On considère deux EDLS homogènes normalisables sur <m>I</m> (qui ne diffèrent que par le coefficient de <m>x</m>) :
            <md>
                <mrow> (H_1)\amp\amp a(t) x'' + b(t) x' + c_1(t) x \amp = 0</mrow> 
                <mrow> (H_2)\amp\amp a(t) x'' + b(t) x' + c_2(t) x \amp = 0
                </mrow>
            </md></p>
            <!-- <aside>
                <p>La relation devient :
                <ul>
                    <li><m>w'(t) = (q_1(t) - q_2(t)) f_1(t) f_2(t)</m> si <m>(H_1)</m> et <m>(H_2)</m> sont normales ;</li>
                    <li><m>(p w)'(t) = (q_1(t) - q_2(t)) f_1(t) f_2(t)</m> si <m>(H_1)</m> et <m>(H_2)</m> sont auto-adjointes.</li>
                </ul></p>
            </aside> -->
            <p>Soient <m>f_1</m> une solution de <m>(H_1)</m> sur <m>I</m> et <m>f_2</m> une solution de <m>(H_2)</m> sur <m>I</m>. En posant <m>w(t) = f_1(t) f_2'(t) - f_2(t) f_1'(t)</m>, on a :
            <me>
                a(t) w'(t) + b(t) w(t) = (c_1(t) - c_2(t)) f_1(t) f_2(t)
            </me>
            c'est l'équation du wronksien croisé des équations <m>(H_1)</m> et <m>(H_2)</m>.
            </p>
            <explanation>
                <p>Par dérivation du déterminant selon les lignes :</p>
                <me>
                    w'(t) = \frac{d}{dt} \begin{vmatrix} f_1(t) \amp f_2(t) \\ f_1'(t) \amp f_2'(t) \end{vmatrix} = \begin{vmatrix} f_1(t) \amp f_2(t) \\ f_1''(t) \amp f_2''(t) \end{vmatrix}
                </me>
                <p>En utilisant les équations différentielles, on obtient :</p>
                <me>
                    w'(t) = \frac{c_1(t) - c_2(t)}{a(t)} f_1(t) f_2(t) - \frac{b(t)}{a(t)} w(t)
                </me>
                <p>d'où le résultat.</p>
            </explanation>
        </li>
    </ol></p>
</assemblage>

        <assemblage>
            <title>Techniques de résolution</title>
            <p>Cette rubrique rassemble quelques remarques pratiques qui peuvent mener à la résolution d'une équation linéaire scalaire du deuxième ordre.</p>
            <aside>
                <p>Il n'existe aucune méthode générale qui permet de résoudre toutes les EDLS d'ordre 2.</p>
            </aside>
            <p>Dans les deux techniques suivantes, on suppose que <m>(E)</m> est normalisable sur <m>I</m> et qu'on connaît une solution <m>f_0</m> de l'équation homogène <m>(H)</m> qui ne s'annule pas sur <m>I</m>.</p>
            <p><ol>
                <li>
                    <title>Méthode de Lagrange</title>  
                    <p>On pose <m>x = f_0(t)y</m> et on remplace dans <m>(E)</m> pour obtenir l'équation :
                    <md><mrow>
                        (E')\amp\amp a(t)f_0(t)y'' + \big(2a(t)f_0'(t) + b(t)f_0(t)\big)y' \amp= \varphi(t)
                    </mrow></md>
                    Cette équation peut être regardée comme une EDLS du premier ordre en <m>y'</m>.</p>
                    <p>Par ailleurs, en multipliant <m>(E')</m> par <m>f_0/a</m>, on obtient  la forme plus mnémonique :</p>
                        <me>
                            \frac{d}{dt}\big(f_0(t)^2y'\big) + r(t)\big(f_0(t)^2y'\big) = \psi(t)
                        </me>
                        <p>où <m>r=b/a</m> et <m>\psi =\varphi/a</m>. Ce qui donne la forme générale de <m>y'</m> :</p>
                        <me>
                            y' = \frac{\e^{-R(t)}}{f_0(t)^2}\Big(\lambda + \int_{t_0}^t \e^{R(s)}\psi(s) \, ds\Big)
                        </me>
                        <p>où <m>\lambda</m> est quelconque dans <m>\K</m> et <m>R</m> est une primitive de <m>r </m> sur <m>I</m>.</p>
                </li>
                <li><title>Méthode du wronskien</title> 
                    <p>L'idée est d'utiliser le fait que les wronskiens de <m>(H)</m> sont les solutions de l'équation <m>a(t)w' + b(t)w = 0</m> :</p> 
                    <aside>
                        <p>La méthode du wronskien permet de résoudre l'équation homogène <m>(H)</m>. Celle de Lagrange permet, si on le désire, de résoudre l'équation complète <m>(E)</m>.</p>
                    </aside>
                    <p>
                    <me>
                        (H)  \Longleftrightarrow \begin{cases}
                        a(t)w' + b(t)w = 0 \\
                        f_0(t)x' - f_0'(t)x = w(t)
                        \end{cases}
                    </me></p>
                </li>
                <li><title>Solutions développables en série entière</title>
                    <aside>
                        <p>L'ensemble <m>S</m> des solutions de l'équation homogène <m>(H)</m> qui sont développables en série entière en <m>0</m> est un sous-espace vectoriel de <m>S_I(H)</m>.</p>
                    </aside>
                    <p>Si les fonctions <m>a</m>, <m>b</m> et <m>c</m> sont polynomiales, il est fort possible que <m>(H)</m> admette des solutions développables en série entière en <m>0</m>, parfois polynomiales.</p>
                </li>
                
            </ol></p>
        </assemblage>

        <!-- Suite du document à convertir... -->

<assemblage>
    <title>Cas d'une EDLS à coefficients constants</title>
    <p>On rappelle ici l'expression des solutions d'une EDLS d'ordre 2 à coefficients constants :
    <me>
        x'' + p x' + q x = \varphi(t)
    </me>
    On note <m>r_1</m> et <m>r_2</m> les racines dans <m>\C</m> du polynôme caractéristique de <m>(H)</m> :
    <me>
        P = X^2 + p X + q
    </me></p>
    <p><ol>
        <li>
            <title>Solutions de l'équation homogène</title>
            <p>les solutions de <m>(H)</m> sur <m>\R</m> à valeurs dans <m>\K</m> sont de la forme :</p>
            <ul>
                <li><m>f(t) = \lambda_1 \e^{r_1 t} + \lambda_2 \e^{r_2 t}</m> si <m>r_1, r_2 \in \K</m> et <m>r_1 \neq r_2</m> ;</li>
                <li><m>f(t) = (\lambda_1 t + \lambda_2) \e^{r t}</m> si <m>r_1 = r_2 = r</m> ;</li>
                <li><m>f(t) = \e^{\alpha t} \big( \lambda_1 \cos(\beta t) + \lambda_2 \sin(\beta t) \big)</m> si <m>\K = \R</m> et <m>r_1 = \overline{r_2} = \alpha + i \beta \notin \R</m>.</li>
            </ul>
            <p>À chaque fois, <m>\lambda_1</m> et <m>\lambda_2</m> sont des scalaires quelconques dans <m>\K</m>.</p>
        </li>
        <li>
            <title>Solution particulière de <m>(E)</m> dans le cas où <m>\varphi(t) = R(t) \e^{\omega t}</m></title> 
            <p>si <m>\varphi(t)</m> est de la forme <m>R(t) \e^{\omega t}</m> où <m>R</m> est une fonction polynomiale à coefficients dans <m>\K</m> et <m>\omega \in \K</m>, alors <m>(E)</m> admet une solution unique de la forme :
            <me>
                f_0(t) = t^{\beta} Q(t) \e^{\omega t}
            </me>
            où <m>\beta</m> est la multiplicité de <m>\omega</m> en tant que racine du polynôme caractéristique <m>P</m> de <m>(H)</m> et <m>Q</m> est un polynôme qui a le même degré que <m>R</m> à déterminer.</p>
        </li>
        <li>
            <title>Solution particulière dans le cas général</title> <p>sur la base de la relation 
            <xref ref="exprsol"/>, 
            <m>t_0</m> étant un point quelconque choisi dans <m>I</m>, <m>(E)</m> admet une solution de la forme :
            <me>
                f_0(t) = \int_{t_0}^t H(t, s) \varphi(s) \, ds
            </me>
            où
            <me>
                H(t, s) = \frac{\begin{vmatrix} f_1(s) \amp f_1(t) \\ f_2(s) \amp f_2(t) \end{vmatrix}}{\begin{vmatrix} f_1(s) \amp f_1'(s) \\ f_2(s) \amp f_2'(s) \end{vmatrix}}
            </me></p>
            <p>Tout calcul fait :
            <ul>
                <li><m>H(t, s) = \frac{\e^{r_2 (t - s)} - \e^{r_1 (t - s)}}{r_2 - r_1}</m> si <m>r_1 \neq r_2</m> ;</li>
                <li><m>H(t, s) = (t - s) \e^{r (t - s)}</m> si <m>r_1 = r_2 = r</m> ;</li>
                <li><m>H(t, s) = \frac{\sin(\beta (t - s))}{\beta} \e^{\alpha (t - s)}</m> si <m>r_1 = \overline{r_2} = \alpha + i \beta \notin \R</m>.</li>
            </ul></p>
        </li>
    </ol></p>
</assemblage>









<example>
    <title>Exemples non génériques</title>
    <ol>
        <li>
            <p>Résoudre en observant que <m>x = t^2 + 1</m> est une solution :</p>
            <me>
                (1 + t^2) x'' - 2 x = 0
            </me>
        </li>
        <li>
            <p>Résoudre en commençant par chercher des solutions polynomiales de l'équation homogène :</p>
            <me>
                (1 + t^2)^2 x'' - 2 t (1 + t^2) x' + 2 (t^2 - 1) x = 1 + t^2
            </me>
        </li>
        <li>
            <p>Résoudre sur <m>]0, 1[</m>, en commençant par chercher les solutions développables en série entière :</p>
            <me>
                t (1 - t) x'' + (1 - 3 t) x' - x = 0
            </me>
        </li>
        <li>
            <p>Résoudre sur <m>]-1, 1[</m>, en commençant par chercher les solutions développables en série entière :</p>
            <me>
                4 (1 - t^2) x'' - 4 t x' + x = 0
            </me>
        </li>
        <li>
            <p>Résoudre sur <m>\R</m>, en posant <m>u = t^2</m> et en étudiant le raccord en <m>0</m> :</p>
            <me>
                t x'' - x' - t^3 x = 0
            </me>
        </li>
    </ol>
</example>

<example>
    <title>Équation de Cauchy-Euler</title>
    <statement>
        <p>
    On considère l'équation 
            <me>
                t^2 x'' + a t x' + b x = 0
            </me>
        L'équation n'est pas normalisable en <m>0</m>.
        </p>
            <p>On cherche les solutions sur <m>]0, +\infty[</m> qui sont de la forme <m>f(t) = t^r</m>. Pour que <m>f</m> soit une solution, il faut et il suffit que <m>r</m> soit une racine du polynôme :
            <me>
                P = X (X - 1) + a X + b
            </me></p>
            <p>Si <m>r_1</m> et <m>r_2</m> sont les racines de <m>P</m> dans <m>\K</m>, les solutions de <m>(H)</m> sur <m>]0, +\infty[</m> sont de la forme :
            <ul>
                <li><m>f(t) = \lambda_1 t^{r_1} + \lambda_2 t^{r_2}</m> si <m>r_1 \neq r_2</m> ;</li>
                <li><m>f(t) = (\lambda_1 + \lambda_2 \ln t) t^r</m> si <m>r_1 = r_2 = r</m> ;</li>
                <li><m>f(t) = \big( \lambda_1 \cos(\im r \ln t) + \lambda_2 \sin(\im r \ln t) \big) t^{\re r}</m> si <m>\K = \R</m> et <m>r = r_1 = \overline{r_2} \notin \R</m>.</li>
            </ul>
            </p>
            <p><alert>Autre méthode :</alert></p>
                <p>Si on pose <m>x(t) = y(\ln t)</m>, alors <m>(E)</m> équivaut sur <m>\R_+^*</m> à l'EDLS à coefficients constants :
                <me>
                    y'' + (a - 1) y' + b y = 0
                </me>
                équation à coefficients constants qui a pour polynôme caractéristique <m>P</m>.</p>
    </statement>
    </example>

    <example><title>Équation d'Airy</title>
    <statement>
        <p>
        On considère l'équation :           
            <me>
                x'' - t x = 0
            </me>
            On cherche les solutions développables en série entière sur <m>\R</m>.</p>
        </statement>
        <solution>
                <p>En remplaçant <m>x</m> par <m>f(t) = \sum_{n=0}^{+\infty} a_n t^n</m> dans <m>(H)</m>, on obtient :
                <me>
                    2 a_2 + \sum_{n=1}^{+\infty} \big( (n + 2) (n + 1) a_{n+2} - a_{n-1} \big) t^n = 0
                </me>
                Ce qui revient à :
                <me>
                    a_2 = 0 \quad \text{et} \quad \forall n \in \N, \; a_{n+3} = \frac{a_n}{(n + 3) (n + 2)}
                </me>
                ou encore, pour tout <m>n \in \N^*</m> :
                <me>
                    a_{3n + 2} = 0, \quad
                    a_{3n + 1} = \frac{2 \cdot 5 \cdots (3n - 1)}{(3n + 1)!} a_1, \quad
                    a_{3n} = \frac{1 \cdot 4 \cdots (3n - 2)}{(3n)!} a_0
                </me>
                Alors les solutions de <m>(H)</m> sur <m>\R</m> sont les fonctions données par :
                <me>
                    f(t) = a_0 f_0(t) + a_1 f_1(t)
                </me>
                où <m>a_0</m> et <m>a_1</m> sont quelconques dans <m>\R</m> et :
                <me>
                    f_0(t) = 1 + \sum_{n=0}^{+\infty} \frac{1 \cdot 4 \cdots (3n - 2)}{(3n)!} t^{3n}, \quad
                    f_1(t) = t + \sum_{n=0}^{+\infty} \frac{2 \cdot 5 \cdots (3n - 1)}{(3n + 1)!} t^{3n + 1}
                </me>
                On notera que les séries entières qui interviennent dans les expressions de <m>f_0</m> et <m>f_1</m> sont bien de rayon de convergence infini.</p>
            </solution>
        </example>

        <example>
            <title>Équation d'Hermite :</title>
            <statement>
                <p>
            <me>
                x'' - 2 t x' + 2 a x = 0
            </me>
            où <m>a</m> est un réel positif ou nul. On cherche les solutions développables en série entière sur <m>\R</m>.</p>
            </statement>
            <solution>
                <p>Comme pour l'équation d'Airy, <m>(H_a)</m> admet effectivement des solutions développables en série entière sur <m>\R</m> 
                    <!-- (exercice <xref ref="exer:eqdse"/>).  -->
                En remplaçant dans <m>(H_a)</m>, on obtient :
                <me>
                    \forall n \in \N, \; (n + 2) (n + 1) a_{n+2} = 2 (n - a) a_n
                </me>
                Et donc pour tout <m>n \in \N^*</m> :
                <me>
                    a_{2n} = \frac{2^{2n}}{(2n)!} (n - (1 + a / 2)) (n - 1 - (1 + a / 2)) \cdots (1 - (1 + a / 2)) a_0
                </me>
                <me>
                    a_{2n + 1} = \frac{2^{2n}}{(2n + 1)!} (n - (a + 1) / 2) (n - 1 - (a + 1) / 2) \cdots (1 - (a + 1) / 2) a_1
                </me>
                Si on prolonge la fonction <m>\Gamma</m> d'Euler sur <m>\R \setminus \Z_-</m> par la relation :
                <me>
                    \forall s \in \R_- \setminus \Z_-, \; \Gamma(s) = \frac{\Gamma(s - E(s))}{s (s + 1) \cdots (s - E(s) - 1)}
                </me>
                De cette manière, elle continuera à vérifier l'équation fonctionnelle :
                <me>
                    \Gamma(s) = (s - 1) \Gamma(s - 1), \quad \forall s \in \R \setminus \Z_-
                </me>
                et donc :
                <me>
                    \forall s \in \R \setminus \Z_-, \forall n \in \N, \; \Gamma(s) = (s - 1) (s - 2) \cdots (s - n) \Gamma(s - n)
                </me>
                Avec respectivement <m>s = \frac{1}{2} a + 1</m> et <m>s = \frac{1}{2} a + \frac{1}{2}</m>, on obtient les écritures :
                <me>
                    a_{2n} = \frac{(-1)^n 2^{2n} \Gamma(\frac{1}{2} a + 1)}{(2n)! \Gamma(\frac{1}{2} a + 1 - n)} a_0, \quad
                    a_{2n + 1} = \frac{(-1)^n 2^{2n} \Gamma(\frac{1}{2} a + \frac{1}{2})}{(2n + 1)! \Gamma(\frac{1}{2} a + \frac{1}{2} - n)} a_1
                </me>
                d'où les solutions de <m>(H_a)</m> :
                <me>
                    f(t) = a_0 f_0(t) + a_1 f_1(t)
                </me>
                avec : 
                <me>
                    f_0(t) = \sum_{n=0}^{+\infty} (-1)^n \frac{2^{2n} \Gamma(\frac{1}{2} a + 1)}{(2n)! \Gamma(\frac{1}{2} a + 1 - n)} t^{2n}, \quad
                    f_1(t) = \sum_{n=0}^{+\infty} (-1)^n \frac{2^{2n} \Gamma(\frac{1}{2} a + \frac{1}{2})}{(2n + 1)! \Gamma(\frac{1}{2} a + \frac{1}{2} - n)} t^{2n + 1}
                </me>
                </p>
                <p>En fait, les écritures précédentes ne sont valables que si <m>\frac{1}{2} a + 1 \notin \N</m> et <m>\frac{1}{2} a + \frac{1}{2} \notin \N</m>. Dans le cas contraire, en revenant aux relations précédentes, on aura :</p>
                <ul>
                    <li>Si <m>\frac{1}{2} a + 1 \in \N</m>, c'est-à-dire <m>a = 2 p</m> avec <m>p \in \N^*</m>, alors :</li>
                    <me>
                        a_{2n} = (-1)^n \frac{2^{2n}}{(2n)!} \frac{p!}{(p - n)!} \quad \text{si } n \leq p
                    </me>
                    <me>
                        a_{2n} = 0 \quad \text{si } n \gt p
                    </me>
                    <p>Dans ce cas, la fonction <m>f_0</m> est polynomiale.</p>
                    <li>Si <m>\frac{1}{2} a + \frac{1}{2} \in \N</m>, c'est-à-dire <m>a = 2 p + 1</m> avec <m>p \in \N^*</m>, alors :</li>
                    <me>
                        a_{2n + 1} = (-1)^n \frac{2^{2n}}{(2n + 1)!} \frac{p!}{(p - n)!} \quad \text{si } n \leq p
                    </me>
                    <me>
                        a_{2n + 1} = 0 \quad \text{si } n \gt p
                    </me>
                    <p>Dans ce cas, c'est la fonction <m>f_1</m> qui est polynomiale.</p>
                </ul>
                <p>On notera que si <m>a</m> est un entier positif, alors <m>(H_a)</m> admet au moins une solution polynomiale. Cette solution est paire si <m>a</m> est pair et impaire si <m>a</m> est impair.</p>
            </solution>
</example>

<example>
    <title>Équation de Tchebytchev</title>
    <statement>
    <p>On considère l'équation différentielle :</p>
    <me>
        (1 - t^2) x'' - t x' + a^2 x = 0
    </me>
    <p>où <m>a</m> est un réel positif. On cherche les solutions développables en série entière sur <m>]-1, 1[</m>.</p>
    </statement>
    <solution>
        <p>En remplaçant <m>x</m> par <m>f(t) = \sum_{n=0}^{+\infty} a_n t^n</m> dans l'équation, on obtient la relation de récurrence :</p>
        <me>
            \forall n \in \N, \; (n + 2) (n + 1) a_{n+2} = (n^2 - a^2) a_n
        </me>
        <p>Pour tout <m>n \in \N^*</m>, on a :
        <me>
            a_{2n} = \frac{(2n - 2)^2 - a^2}{(2n) (2n - 1)} \frac{(2n - 4)^2 - a^2}{(2n - 2) (2n - 3)} \cdots \frac{-a^2}{2 \cdot 1} a_0 = \frac{a_0}{(2n)!} \prod_{k=0}^{n-1} ((2k)^2 - a^2)
        </me>
        <me>
            a_{2n + 1} = \frac{(2n - 1)^2 - a^2}{(2n + 1) (2n)} \frac{(2n - 3)^2 - a^2}{(2n - 1) (2n - 2)} \cdots \frac{1 - a^2}{3 \cdot 2} a_1 = \frac{a_1}{(2n + 1)!} \prod_{k=0}^{n-1} ((2k + 1)^2 - a^2)
        </me></p>
        <p>Par suite, les solutions de l'équation sur <m>]-1, 1[</m> sont les fonctions données par :
        <me>
            f(t) = a_0 f_0(t) + a_1 f_1(t)
        </me>
        où :
        <md>
            <mrow> f_0(t) \amp = 1 + \sum_{n=1}^{+\infty} \prod_{k=0}^{n-1} \big((2k)^2 - a^2\big) \frac{t^{2n}}{(2n)!}</mrow>
            <mrow>f_1(t) \amp = t + \sum_{n=1}^{+\infty} \prod_{k=0}^{n-1} \big((2k + 1)^2 - a^2\big) \frac{t^{2n + 1}}{(2n + 1)!}</mrow>
        </md></p>
        <aside>
            <p>On peut de manière directe prouver que l'équation admet au moins une solution polynomiale si <m>a = m \in \N</m> : c'est le polynôme de Tchebychev <m>T_m</m> défini par :
            <me>
                \forall \theta \in \R, \; T_m(\cos \theta) = \cos(m \theta)
            </me></p>
        </aside>
        <p>On notera que :</p>
        <ul>
            <li>Si <m>a</m> est un entier positif pair, <m>a = 2p</m> avec <m>p \in \N</m>, alors <m>a_{2n} = 0</m> si <m>n \geq p</m> et <m>f_0</m> est une fonction polynomiale paire de degré <m>2p</m>.</li>
            <li>Si <m>a</m> est un entier positif impair, <m>a = 2p + 1</m> avec <m>p \in \N</m>, alors <m>a_{2n + 1} = 0</m> si <m>n \geq p</m> et <m>f_1</m> est une fonction polynomiale impaire de degré <m>2p + 1</m>.</li>
            <li>Si <m>a</m> est un entier positif, alors l'équation admet au moins une solution polynomiale.</li>
        </ul>
    </solution>
</example>



<assemblage>
    <title>Transformation d'une EDLS du second ordre</title>
    <p>Pour la simplification de l'étude de certaines proriétés des solutions d'une EDLS du second ordre, on la transforme en des formes plus adaptées. La suite expose les deux transformations les plus utilisées.
    </p>  
    <p><ol> 
        <li>
            <title>Forme normale d'une EDLS du deuxième ordre</title> <p>On suppose que les fonctions <m>a</m> et <m>b</m> sont de classe <m>\mathcal{C}^1</m>. Alors il existe une fonction <m>k</m> de classe <m>\mathcal{C}^2</m> qui ne s'annule pas sur <m>I</m> telle qu'en posant <m>x = k(t) y</m>, <m>(E)</m> soit équivalente à une équation de la forme :
            <md><mrow>
                (EN)\amp\amp\amp\amp
                y'' + q(t) y \amp= \psi(t)\mkern100mu
                </mrow>
            </md>
            Cette équation est dite une forme normale de l'équation <m>(E)</m>.</p>
            <explanation>
                <p>Supposons pour l'instant qu'une telle fonction existe. On a alors :</p>
                <me>
                    x = k(t) y, \quad x' = k(t) y' + k'(t) y(t), \quad x'' = k(t) y'' + 2 k'(t) y' + k''(t) y
                </me>
                <p><m>(E)</m> sera de ce fait équivalente à l'EDLS d'inconnue <m>y</m> :
                <me>
                    a(t) k(t) y'' + \big(2 a(t) k'(t) + b(t) k(t)\big) y' + \big(a(t) k''(t) + b(t) k'(t) + c(t) k(t)\big) y = \varphi(t)
                </me></p>
                 <aside>
                <p>L'équation du wronskien de <m>(EN)</m> est <m>w' = 0</m>. Tous ses wronskiens sont constants.</p>
            </aside>
                <p>En choisissant <m>k</m> comme une solution non nulle de l'équation du premier ordre :</p>
                <me>
                    2 a(t) k' + b(t) k = 0
                </me>
                <p>elle sera effectivement de classe <m>\mathcal{C}^2</m> car <m>a</m> et <m>b</m> sont supposées de classe <m>\mathcal{C}^1</m>, ne s'annulera pas sur <m>I</m> et on aura :
                <me>
                    (E)  \Longleftrightarrow y'' + q(t) y = \psi(t)
                </me></p>
                <aside>
                <p>Les équations de type <m>x'' + q(t) x = 0</m> sont souvent associées à l'étude de la distribution des zéros d'une solution sur <m>I</m>, de l'existence de solutions périodiques dans le cas où la fonction <m>q</m> est périodique...</p>
                </aside>
                <p>avec :
                <me>
                    q(t) = \frac{a(t) k''(t) + b(t) k'(t) + c(t) k(t)}{a(t) k(t)}, \quad \psi(t) = \frac{\varphi(t)}{a(t) k(t)}
                </me></p>
            </explanation>      
        </li>
        <li>
            <title>Forme auto-adjointe</title>
            <p> On suppose que la fonction <m>a</m> est de classe <m>\mathcal{C}^1</m> sur <m>I</m>. Alors il existe une fonction <m>p</m> de classe <m>\mathcal{C}^1</m> ne s'annulant pas sur <m>I</m> et une fonction <m>q</m> continue sur <m>I</m> telle que <m>(H)</m> soit équivalente à l'équation :</p>
            <aside>
                <p>L'équation du wronskien de <m>(HA)</m> est <m>(p w)' = 0</m>. Tous les wronskiens de <m>(HA)</m> sont proportionnels à <m>\frac{1}{p}</m>.</p>
            </aside>
            <p>
            <me>
                (p(t) x')' + q(t) x = 0
            </me></p>
            
            <p>Cette équation est dite une forme auto-adjointe de l'équation homogène <m>(H)</m>.</p>
            <aside>
                <p>Contrairement à une forme normale de <m>(H)</m>, on conserve la même fonction inconnue <m>x</m>.</p>
            </aside>
            <explanation>
                <p>Considérons pour l'instant une fonction <m>\sigma</m> quelconque de classe <m>\mathcal{C}^1</m> et ne s'annulant pas sur <m>I</m>. Alors :</p>
                <me>
                    (H)  \Longleftrightarrow a(t) \sigma(t) x'' + b(t) \sigma(t) x' + c(t) \sigma(t) x = 0
                </me>
                <p>Si on choisit <m>\sigma</m> comme une solution non nulle sur <m>I</m> de l'EDLS du premier ordre :</p>
                <me>
                    a(t) \sigma' + (a'(t) - b(t)) \sigma = 0
                </me>
                <p>on aura <m>(a \sigma)' = b \sigma</m> et <m>(H)</m> se ramène donc à :</p>
                <me>
                    (a(t) \sigma(t) x')' + c(t) \sigma(t) x = 0
                </me>
                <p>Il suffit de poser <m>p = a \sigma</m> qui est bien de classe <m>\mathcal{C}^1</m> et ne s'annule pas sur <m>I</m> et <m>q = c \sigma</m>.</p>
            </explanation>
        </li>
        </ol></p>
</assemblage>

</section>